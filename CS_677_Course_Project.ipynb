{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CS 677 Course Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1EGva0ajTlBrxfOvAxzV8rW3WOE7_-C_6",
      "authorship_tag": "ABX9TyN2ubNGdxKE1mapNEB1aXg5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamccauley/rfi-detection-project/blob/main/CS_677_Course_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56LPRWec3MOY"
      },
      "source": [
        "README - R-NET, LSTM, CNN-LSTM, & Gaussian Process Model Implementations\n",
        " \n",
        "RFI Detection in Radio Astronomy Data  \n",
        "Morgan Dameron & John McCauley\n",
        "\n",
        "NOTE: The code in this notebook was written by John McCauley\n",
        "\n",
        "This document along with the provided code and data describes how to run the experiements used in this project. A list of all required python packages/modules is included at the end of the notebook. \n",
        "\n",
        "I have tried to format filepath references to work as written, but I cannot confirm this. As such to properly load the sample data, some filename references in the code may need changed. Those lines are marked with comments indicating such in the following code blocks, just in case here are some instructions on changing the file location references:\n",
        "\n",
        "Directly below the comment \"#Load PSD Data and Masks (s_16 and TONE)\" in each of the four main code blocks there are four lines of code in which filepaths are referenced. Those lines are:\n",
        "\n",
        "\"s16_filepath = \"/Data/s_16bit.npy\"\n",
        "s16flag_filepath = \"/Data/s_16bit_flags.npy\"\n",
        "tone_filepath = \"/Data/TONE_Data.npy\"\n",
        "toneflag_filepath = \"/Data/TONE_data_flags.npy\"\"\n",
        "\n",
        "\n",
        "Please change the file path references here if the current reference is incorrect.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Section 1. R-Net\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The first block of code instantiates the R-Net5 model as described in the original publication. Please pay special attention to the comments in the code about the input shape of the network, depending on which data set is to be used, the input shape must be adjusted. The code block then loads in the sample data, performs the necessary transformations, splits the data into train and test splits, and begins a training session on the data. Once training is complete, the model is saved, predicted values for the test set are calculated, and classification metrics are calculated.\n",
        "\n",
        "Currently the model will train and test on the sample TONE data, to change this please replace the line containing the input layer of R-Net to\n",
        "\n",
        "\"input = keras.Input(shape=(4096, 512, 1))\"\n",
        "\n",
        "As well as replace the lines below these comments\n",
        "\n",
        "\"#concatenate data into overall data matrix  \n",
        "\"#change which vars are in the concatenate block to train/test on a different dataset\n",
        "\n",
        "to this - \n",
        "\n",
        "\"psdData = np.concatenate((psd0Blocks, psd1Blocks),axis=0)  \n",
        "psdLabels = np.concatenate((maskPsd0Blocks, maskPsd1Blocks), axis=0) \n",
        "\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP9mH2j5aeUo"
      },
      "source": [
        "\n",
        "##### RFI DETECTION IN RADIO ASTRONOMY DATA #####\n",
        "##### Morgan Dameron & John McCauley #####\n",
        "\n",
        "# R-Net Implementation - Architecture for R-Net5\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "input = keras.Input(shape=(1024, 512, 1)) #Change input shape depending on which data being used. s_16 = (4096, 512, 1), TONE = (1024, 512, 1)\n",
        "xp = layers.Conv2D(filters=12,kernel_size=5,strides=(1, 1),padding='same')(input)\n",
        "x = layers.BatchNormalization()(xp)\n",
        "x = layers.ReLU()(x)\n",
        "x1 = layers.Conv2D(filters=12,kernel_size=5,strides=(1, 1),padding='same')(x)\n",
        "x1 = layers.BatchNormalization()(x1)\n",
        "x1 = layers.ReLU()(x1)\n",
        "x2 = layers.Conv2D(filters=12,kernel_size=5,strides=(1, 1),padding='same')(x1)\n",
        "x2 = layers.BatchNormalization()(x2)\n",
        "x2 = layers.ReLU()(x2)\n",
        "x3 = x2+xp\n",
        "x4 = layers.Conv2D(filters=12,kernel_size=5,strides=(1, 1),padding='same')(x3)\n",
        "x4 = layers.BatchNormalization()(x4)\n",
        "x4 = layers.ReLU()(x4)\n",
        "x5 = layers.Conv2D(filters=1,kernel_size=5,strides=(1, 1),padding='same')(x4)\n",
        "x5 = layers.BatchNormalization()(x5)\n",
        "x5 = layers.ReLU()(x5)\n",
        "\n",
        "x_out = layers.Conv2D(filters=1,kernel_size=5,strides=(1, 1),padding='same',\n",
        "            activation=tf.nn.relu)(x5)\n",
        "\n",
        "model = keras.Model(inputs=input,outputs=x_out)\n",
        "\n",
        "model.summary()\n",
        "keras.utils.plot_model(model)\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.MeanSquaredError(),\n",
        "    optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "# R-Net Implementation - Load all data\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "#Load PSD Data and Masks (s_16 and TONE)\n",
        "s16_filepath = \"/Data/s_16bit.npy\"\n",
        "s16flag_filepath = \"/Data/s_16bit_flags.npy\"\n",
        "tone_filepath = \"/Data/TONE_Data.npy\"\n",
        "toneflag_filepath = \"/Data/TONE_data_flags.npy\"\n",
        "\n",
        "psd = np.load(s16_filepath) #load the .npy file, filepath may need changed\n",
        "\n",
        "psd0Blocks = np.stack(np.split(psd[:,0:3072,0],6,axis=1)) #split into 127 blocks along the time axis for each polarity\n",
        "psd1Blocks = np.stack(np.split(psd[:,0:3072,1],6,axis=1))\n",
        "\n",
        "psd0Blocks = np.array(psd0Blocks, dtype = np.float32)\n",
        "psd1Blocks = np.array(psd1Blocks, dtype = np.float32)\n",
        "\n",
        "maskPsd = np.load(s16flag_filepath) #load the SK g.t., filepath may need changed\n",
        "\n",
        "\n",
        "Mask0 = np.swapaxes(maskPsd[0:3072,:,0],0,1)\n",
        "Mask1 = np.swapaxes(maskPsd[0:3072,:,1],0,1)\n",
        "\n",
        "#tile ground truth labels to match input size\n",
        "maskLab0 = []\n",
        "maskLab1 = []\n",
        "for i in range(np.shape(Mask0)[0]):\n",
        "  x1 = Mask0[i,:]\n",
        "  y1 = np.tile(x1, (512, 1))\n",
        "  x2 = Mask1[i,:]\n",
        "  y2 = np.tile(x2, (512, 1))\n",
        "  maskLab0.append(np.transpose(y1))\n",
        "  maskLab1.append(np.transpose(y2))\n",
        "\n",
        "maskPsd0Blocks = np.array(maskLab0,dtype=np.float32)\n",
        "maskPsd1Blocks = np.array(maskLab1,dtype=np.float32)\n",
        "\n",
        "tonePsd = np.load(tone_filepath) #load TONE data, filepath may need changed\n",
        "toneMask = np.load(toneflag_filepath) #load TONE SK g.t., filepath may need changed\n",
        "\n",
        "tonePsd0Blocks = np.stack(np.split(tonePsd[:,0:3072,0],6,axis=1)) #split into 127 blocks along the time axis for each polarity\n",
        "tonePsd1Blocks = np.stack(np.split(tonePsd[:,0:3072,1],6,axis=1))\n",
        "\n",
        "tonePsd0Blocks = np.array(tonePsd0Blocks, dtype = np.float32)\n",
        "tonePsd1Blocks = np.array(tonePsd1Blocks, dtype = np.float32)\n",
        "\n",
        "toneMask0 = np.swapaxes(toneMask[0:3072,:,0],0,1)\n",
        "toneMask1 = np.swapaxes(toneMask[0:3072,:,1],0,1)\n",
        "\n",
        "#tile ground truth labels to match input size\n",
        "toneLab0 = []\n",
        "toneLab1 = []\n",
        "for i in range(np.shape(toneMask0)[0]):\n",
        "  x1 = toneMask0[i,:]\n",
        "  y1 = np.tile(x1, (512, 1))\n",
        "  x2 = toneMask1[i,:]\n",
        "  y2 = np.tile(x2, (512, 1))\n",
        "  toneLab0.append(np.transpose(y1))\n",
        "  toneLab1.append(np.transpose(y2))\n",
        "\n",
        "toneMask0Blocks = np.array(toneLab0,dtype=np.float32)\n",
        "toneMask1Blocks = np.array(toneLab1,dtype=np.float32)\n",
        "\n",
        "#concatenate data into overall data matrix\n",
        "#change which vars are in the concatenate block to train/test on a different dataset\n",
        "psdData = np.concatenate((tonePsd0Blocks, tonePsd1Blocks),axis=0) # tonePsd0Blocks, tonePsd1Blocks psd0Blocks, psd1Blocks\n",
        "psdLabels = np.concatenate((toneMask0Blocks, toneMask1Blocks), axis=0) # toneMask0Blocks, toneMask1Blocks maskPsd0Blocks, maskPsd1Blocks\n",
        "\n",
        "del psd, maskPsd, Mask0, Mask1, toneMask0Blocks, toneMask1Blocks, tonePsd, toneMask, maskLab1, toneLab0 #delete all old variables to save on RAM\n",
        "del psd0Blocks, psd1Blocks, maskPsd0Blocks, maskPsd1Blocks, toneMask0, toneMask1, maskLab0, toneLab1\n",
        "\n",
        "#normalize all samples\n",
        "normPsd = []\n",
        "for i in range(np.shape(psdData)[0]):\n",
        "  sample = psdData[i,:,:]\n",
        "  sample = sample - np.min(sample)\n",
        "  sample = sample / np.max(sample)\n",
        "  normPsd.append(sample)\n",
        "\n",
        "#split into train test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(normPsd, psdLabels, test_size = 0.2, random_state=1)\n",
        "\n",
        "X_train = np.expand_dims(X_train, axis=3)\n",
        "X_test = np.expand_dims(X_test, axis=3)\n",
        "Y_train = np.expand_dims(Y_train, axis=3)\n",
        "Y_test = np.expand_dims(Y_test, axis=3)\n",
        "\n",
        "##### Train & Test R-Net5 #####\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#model = keras.models.load_model(\"/content/drive/Shareddrives/CS 677/Project/R-Net_s16sk/\") #load an old model to train further\n",
        "\n",
        "history = model.fit(X_train, Y_train, batch_size=10, epochs=15, validation_split=0.2) #Change params here for the situation (i.e. smaller batch size for s_16 data, smaller number of epochs for further training on old model) \n",
        "\n",
        "model.save(\"/\") #make sure to change model save location for a new model\n",
        "\n",
        "preds = model.predict(X_test,batch_size=10) #get predicted values from trained model\n",
        "\n",
        "print(np.shape(preds))\n",
        "\n",
        "##### Get classification metrics from predicted vals #####\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report,auc,roc_curve\n",
        "\n",
        "#Create Binary Mask from Predicted Values for Each Sample\n",
        "maskedPreds = []\n",
        "for i in range(np.shape(preds)[0]):\n",
        "  toMask = preds[i,:,:,0]\n",
        "  thresh = 0.6 #fine tune threshold for best results\n",
        "  mask = np.where(toMask >= thresh, 1, 0) \n",
        "  maskedPreds.append(mask)\n",
        "\n",
        "maskedPreds = np.stack(maskedPreds)\n",
        "\n",
        "vectTrue = np.ravel(Y_test) #vectorize preds and labels for classification metrics\n",
        "vectPreds = np.ravel(maskedPreds)\n",
        "\n",
        "print(classification_report(vectTrue,vectPreds)) #calculate classification metrics\n",
        "\n",
        "#Combine all time blocks for visualization, both preds and true labels\n",
        "reMask = []\n",
        "reTrue = []\n",
        "for i in range(np.shape(maskedPreds)[0]):\n",
        "  bb = np.transpose(maskedPreds[i,:,:])\n",
        "  cc = np.transpose(Y_test[i,:,:,0])\n",
        "  reMask.append(bb)\n",
        "  reTrue.append(cc)\n",
        "\n",
        "reMask = np.concatenate(reMask)\n",
        "reTrue = np.concatenate(reTrue)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_PEsNa-wYpg"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "\n",
        "Section 2. LSTM\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The second block of code performs training and testing of the vanilla LSTM model. The code block loads in the sample data, performs the necessary transformations, splits the data into train and test splits, and begins a training session on the data. Once training is complete, the model is saved, predicted values for the test set are calculated, and classification metrics are calculated. \n",
        "\n",
        "Currently the model will train and test on the sample TONE data, to change this please replace the lines below the comments\n",
        "\n",
        "\"#concatenate data into overall data matrix\"  \n",
        "\"#change which vars are in the concatenate block to train/test on a different dataset\"\n",
        "\n",
        "to this - \n",
        "\n",
        "\"psdData = np.concatenate((psd0Blocks, psd1Blocks),axis=0)  \n",
        "psdLabels = np.concatenate((maskPsd0Blocks, maskPsd1Blocks), axis=0) \n",
        "\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av0OeVPV4imN"
      },
      "source": [
        "##### CS 677 COURSE PROJECT #####\n",
        "##### RFI DETECTION IN RADIO ASTRONOMY DATA #####\n",
        "##### Morgan Dameron & John McCauley #####\n",
        "\n",
        "##### LSTM Classification #####\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#Load PSD Data and Masks (s_16 and TONE)\n",
        "s16_filepath = \"/Data/s_16bit.npy\"\n",
        "s16flag_filepath = \"/Data/s_16bit_flags.npy\"\n",
        "tone_filepath = \"/Data/TONE_Data.npy\"\n",
        "toneflag_filepath = \"/Data/TONE_data_flags.npy\"\n",
        "\n",
        "psd = np.load(s16_filepath) #load the .npy file, filepath may need changed\n",
        "\n",
        "psd0Blocks = np.stack(np.split(psd[:,0:3072,0],6,axis=1)) #split into 127 blocks along the time axis for each polarity\n",
        "psd1Blocks = np.stack(np.split(psd[:,0:3072,1],6,axis=1))\n",
        "\n",
        "psd0Blocks = np.array(psd0Blocks, dtype = np.float32)\n",
        "psd1Blocks = np.array(psd1Blocks, dtype = np.float32)\n",
        "\n",
        "maskPsd = np.load(s16flag_filepath) #load the SK g.t., filepath may need changed\n",
        "\n",
        "\n",
        "Mask0 = np.swapaxes(maskPsd[0:3072,:,0],0,1)\n",
        "Mask1 = np.swapaxes(maskPsd[0:3072,:,1],0,1)\n",
        "\n",
        "#tile ground truth labels to match input size\n",
        "maskLab0 = []\n",
        "maskLab1 = []\n",
        "for i in range(np.shape(Mask0)[0]):\n",
        "  x1 = Mask0[i,:]\n",
        "  y1 = np.tile(x1, (512, 1))\n",
        "  x2 = Mask1[i,:]\n",
        "  y2 = np.tile(x2, (512, 1))\n",
        "  maskLab0.append(np.transpose(y1))\n",
        "  maskLab1.append(np.transpose(y2))\n",
        "\n",
        "maskPsd0Blocks = np.array(maskLab0,dtype=np.float32)\n",
        "maskPsd1Blocks = np.array(maskLab1,dtype=np.float32)\n",
        "\n",
        "tonePsd = np.load(tone_filepath) #load TONE data, filepath may need changed\n",
        "toneMask = np.load(toneflag_filepath) #load TONE SK g.t., filepath may need changed\n",
        "\n",
        "tonePsd0Blocks = np.stack(np.split(tonePsd[:,0:3072,0],6,axis=1)) #split into 127 blocks along the time axis for each polarity\n",
        "tonePsd1Blocks = np.stack(np.split(tonePsd[:,0:3072,1],6,axis=1))\n",
        "\n",
        "tonePsd0Blocks = np.array(tonePsd0Blocks, dtype = np.float32)\n",
        "tonePsd1Blocks = np.array(tonePsd1Blocks, dtype = np.float32)\n",
        "\n",
        "toneMask0 = np.swapaxes(toneMask[0:3072,:,0],0,1)\n",
        "toneMask1 = np.swapaxes(toneMask[0:3072,:,1],0,1)\n",
        "\n",
        "#tile ground truth labels to match input size\n",
        "toneLab0 = []\n",
        "toneLab1 = []\n",
        "for i in range(np.shape(toneMask0)[0]):\n",
        "  x1 = toneMask0[i,:]\n",
        "  y1 = np.tile(x1, (512, 1))\n",
        "  x2 = toneMask1[i,:]\n",
        "  y2 = np.tile(x2, (512, 1))\n",
        "  toneLab0.append(np.transpose(y1))\n",
        "  toneLab1.append(np.transpose(y2))\n",
        "\n",
        "toneMask0Blocks = np.array(toneLab0,dtype=np.float32)\n",
        "toneMask1Blocks = np.array(toneLab1,dtype=np.float32)\n",
        "\n",
        "#concatenate data into overall data matrix\n",
        "#change which vars are in the concatenate block to train/test on a different dataset\n",
        "psdData = np.concatenate((tonePsd0Blocks, tonePsd1Blocks),axis=0) # tonePsd0Blocks, tonePsd1Blocks psd0Blocks, psd1Blocks\n",
        "psdLabels = np.concatenate((toneMask0Blocks, toneMask1Blocks), axis=0) # toneMask0Blocks, toneMask1Blocks maskPsd0Blocks, maskPsd1Blocks\n",
        "\n",
        "del psd, maskPsd, Mask0, Mask1, toneMask0Blocks, toneMask1Blocks, tonePsd, toneMask, maskLab1, toneLab0 #delete all old variables to save on RAM\n",
        "del psd0Blocks, psd1Blocks, maskPsd0Blocks, maskPsd1Blocks, toneMask0, toneMask1, maskLab0, toneLab1\n",
        "\n",
        "#normalize all samples\n",
        "normPsd = []\n",
        "for i in range(np.shape(psdData)[0]):\n",
        "  sample = psdData[i,:,:]\n",
        "  sample = sample - np.min(sample)\n",
        "  sample = sample / np.max(sample)\n",
        "  normPsd.append(sample)\n",
        "\n",
        "normPsd = np.array(normPsd, dtype=np.float32) \n",
        "print(np.shape(normPsd))\n",
        "\n",
        "#reshape samples into univariate time-series\n",
        "dat = []\n",
        "lab = []\n",
        "for i in range(np.shape(normPsd)[0]):\n",
        "  for j in range(1024):\n",
        "    samp = normPsd[i,j,:]\n",
        "    label = psdLabels[i,j,0]\n",
        "    dat.append(samp)\n",
        "    lab.append(label)\n",
        "\n",
        "dat = np.array(dat, dtype=np.float32) \n",
        "lab = np.array(lab, dtype=np.float32)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dat, lab, test_size = 0.2, random_state=42)\n",
        "\n",
        "\n",
        "#Define LSTM Model\n",
        "input = keras.Input(shape=(512, 1))\n",
        "x1 = keras.layers.LSTM(50)(input)\n",
        "x2 = keras.layers.Dropout(0.2)(x1)\n",
        "x3 = keras.layers.Dense(50, activation='relu')(x2)\n",
        "x4 = keras.layers.Dense(1, activation='sigmoid')(x3)\n",
        "\n",
        "model = keras.Model(inputs=input,outputs=x4)\n",
        "model.summary()\n",
        "keras.utils.plot_model(model)\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "history = model.fit(X_train,Y_train,batch_size=2048, epochs=50, validation_split=0.2)\n",
        "\n",
        "model.save(\"/\")\n",
        "\n",
        "preds = model.predict(X_test,batch_size=512)\n",
        "\n",
        "print(np.shape(preds))\n",
        "\n",
        "##### Classification Metrics for LSTM and CNN LSTM #####\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "thresh = 0.6 #change thresh value to fine tune classification results\n",
        "binPreds = np.where(preds>thresh,1,0)\n",
        "\n",
        "print(classification_report(Y_test, binPreds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_EbG8wBwXHA"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "\n",
        "Section 3. CNN-LSTM\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The third block of code performs training and testing of the CNN-LSTM model. This code block is structured in the same way as the LSTM block. The block loads in the sample data, performs the necessary transformations, splits the data into train and test splits, and begins a training session on the data. Once training is complete, the model is saved, predicted values for the test set are calculated, and classification metrics are calculated.\n",
        "\n",
        "Currently the model will train and test on the sample TONE data, to change this please replace the lines below the comments\n",
        "\n",
        "\"#concatenate data into overall data matrix\"  \n",
        "\"#change which vars are in the concatenate block to train/test on a different dataset\"\n",
        "\n",
        "to this - \n",
        "\n",
        "\"psdData = np.concatenate((psd0Blocks, psd1Blocks),axis=0)  \n",
        "psdLabels = np.concatenate((maskPsd0Blocks, maskPsd1Blocks), axis=0) \n",
        "\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwrjBJ0-VGMc"
      },
      "source": [
        "##### CS 677 COURSE PROJECT #####\n",
        "##### RFI DETECTION IN RADIO ASTRONOMY DATA #####\n",
        "##### Morgan Dameron & John McCauley #####\n",
        "\n",
        "##### CNN-LSTM Implementation #####\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "\n",
        "#Load PSD Data and Masks (s_16 and TONE)\n",
        "s16_filepath = \"/Data/s_16bit.npy\"\n",
        "s16flag_filepath = \"/Data/s_16bit_flags.npy\"\n",
        "tone_filepath = \"/Data/TONE_Data.npy\"\n",
        "toneflag_filepath = \"/Data/TONE_data_flags.npy\"\n",
        "\n",
        "psd = np.load(s16_filepath) #load the .npy file, filepath may need changed\n",
        "\n",
        "psd0Blocks = np.stack(np.split(psd[:,0:3072,0],6,axis=1)) #split into 127 blocks along the time axis for each polarity\n",
        "psd1Blocks = np.stack(np.split(psd[:,0:3072,1],6,axis=1))\n",
        "\n",
        "psd0Blocks = np.array(psd0Blocks, dtype = np.float32)\n",
        "psd1Blocks = np.array(psd1Blocks, dtype = np.float32)\n",
        "\n",
        "maskPsd = np.load(s16flag_filepath) #load the SK g.t., filepath may need changed\n",
        "\n",
        "\n",
        "Mask0 = np.swapaxes(maskPsd[0:3072,:,0],0,1)\n",
        "Mask1 = np.swapaxes(maskPsd[0:3072,:,1],0,1)\n",
        "\n",
        "#tile ground truth labels to match input size\n",
        "maskLab0 = []\n",
        "maskLab1 = []\n",
        "for i in range(np.shape(Mask0)[0]):\n",
        "  x1 = Mask0[i,:]\n",
        "  y1 = np.tile(x1, (512, 1))\n",
        "  x2 = Mask1[i,:]\n",
        "  y2 = np.tile(x2, (512, 1))\n",
        "  maskLab0.append(np.transpose(y1))\n",
        "  maskLab1.append(np.transpose(y2))\n",
        "\n",
        "maskPsd0Blocks = np.array(maskLab0,dtype=np.float32)\n",
        "maskPsd1Blocks = np.array(maskLab1,dtype=np.float32)\n",
        "\n",
        "tonePsd = np.load(tone_filepath) #load TONE data, filepath may need changed\n",
        "toneMask = np.load(toneflag_filepath) #load TONE SK g.t., filepath may need changed\n",
        "\n",
        "tonePsd0Blocks = np.stack(np.split(tonePsd[:,0:3072,0],6,axis=1)) #split into 127 blocks along the time axis for each polarity\n",
        "tonePsd1Blocks = np.stack(np.split(tonePsd[:,0:3072,1],6,axis=1))\n",
        "\n",
        "tonePsd0Blocks = np.array(tonePsd0Blocks, dtype = np.float32)\n",
        "tonePsd1Blocks = np.array(tonePsd1Blocks, dtype = np.float32)\n",
        "\n",
        "toneMask0 = np.swapaxes(toneMask[0:3072,:,0],0,1)\n",
        "toneMask1 = np.swapaxes(toneMask[0:3072,:,1],0,1)\n",
        "\n",
        "#tile ground truth labels to match input size\n",
        "toneLab0 = []\n",
        "toneLab1 = []\n",
        "for i in range(np.shape(toneMask0)[0]):\n",
        "  x1 = toneMask0[i,:]\n",
        "  y1 = np.tile(x1, (512, 1))\n",
        "  x2 = toneMask1[i,:]\n",
        "  y2 = np.tile(x2, (512, 1))\n",
        "  toneLab0.append(np.transpose(y1))\n",
        "  toneLab1.append(np.transpose(y2))\n",
        "\n",
        "toneMask0Blocks = np.array(toneLab0,dtype=np.float32)\n",
        "toneMask1Blocks = np.array(toneLab1,dtype=np.float32)\n",
        "\n",
        "#concatenate data into overall data matrix\n",
        "#change which vars are in the concatenate block to train/test on a different dataset\n",
        "psdData = np.concatenate((tonePsd0Blocks, tonePsd1Blocks),axis=0) # tonePsd0Blocks, tonePsd1Blocks psd0Blocks, psd1Blocks\n",
        "psdLabels = np.concatenate((toneMask0Blocks, toneMask1Blocks), axis=0) # toneMask0Blocks, toneMask1Blocks maskPsd0Blocks, maskPsd1Blocks\n",
        "\n",
        "del psd, maskPsd, Mask0, Mask1, toneMask0Blocks, toneMask1Blocks, tonePsd, toneMask, maskLab1, toneLab0 #delete all old variables to save on RAM\n",
        "del psd0Blocks, psd1Blocks, maskPsd0Blocks, maskPsd1Blocks, toneMask0, toneMask1, maskLab0, toneLab1\n",
        "\n",
        "#normalize all samples\n",
        "normPsd = []\n",
        "for i in range(np.shape(psdData)[0]):\n",
        "  sample = psdData[i,:,:]\n",
        "  sample = sample - np.min(sample)\n",
        "  sample = sample / np.max(sample)\n",
        "  normPsd.append(sample)\n",
        "\n",
        "normPsd = np.array(normPsd, dtype=np.float32) \n",
        "print(np.shape(normPsd))\n",
        "\n",
        "#reshape samples into univariate time-series\n",
        "dat = []\n",
        "lab = []\n",
        "for i in range(np.shape(normPsd)[0]):\n",
        "  for j in range(1024):\n",
        "    samp = normPsd[i,j,:]\n",
        "    label = psdLabels[i,j,0]\n",
        "    dat.append(samp)\n",
        "    lab.append(label)\n",
        "\n",
        "dat = np.array(dat, dtype=np.float32) \n",
        "lab = np.array(lab, dtype=np.float32)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dat, lab, test_size = 0.2, random_state=42)\n",
        "\n",
        "X_train = np.reshape(np.array(X_train, dtype=np.float32),(np.shape(X_train)[0], 4, 128, 1)) \n",
        "X_test = np.reshape(np.array(X_test, dtype=np.float32),(np.shape(X_test)[0], 4, 128, 1))\n",
        "Y_train = np.array(Y_train, dtype=np.float32)\n",
        "Y_test = np.array(Y_test, dtype=np.float32)\n",
        "\n",
        "\n",
        "print(np.shape(X_train))\n",
        "print(np.shape(X_test))\n",
        "print(np.shape(Y_train))\n",
        "print(np.shape(Y_test))\n",
        "\n",
        "#Define CNN-LSTM Model\n",
        "model = Sequential()\n",
        "model.add(TimeDistributed(Conv1D(filters=12, kernel_size=3, activation='relu'), input_shape=(None,128,1)))\n",
        "model.add(TimeDistributed(Conv1D(filters=12, kernel_size=3, activation='relu')))\n",
        "model.add(TimeDistributed(Dropout(0.5)))\n",
        "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "history = model.fit(X_train,Y_train,batch_size=1024, epochs=50, validation_split=0.2)\n",
        "\n",
        "model.save(\"/content/drive/Shareddrives/CS 677/Project/CNN_LSTM_TONE/\")\n",
        "\n",
        "preds = model.predict(X_test,batch_size=512)\n",
        "\n",
        "print(np.shape(preds))\n",
        "\n",
        "##### Classification Metrics for LSTM and CNN LSTM #####\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "thresh = 0.6 #change thresh value to fine tune classification results\n",
        "binPreds = np.where(preds>thresh,1,0)\n",
        "\n",
        "print(classification_report(Y_test, binPreds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWD3K2mMwVwB"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "\n",
        "Section 4. Gaussian Process Classifier\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The fourth block of code performs training and testing of the Gaussian Process model. This code block is structured in the same way as the previous two blocks. The block loads in the sample data, performs the necessary transformations, splits the data into train and test splits, and begins a training session on the data. Once training is complete, predicted values for the test set are calculated, and classification metrics are calculated.\n",
        "\n",
        "Currently the model will train and test on the sample TONE data, to change this please replace the lines below the comments\n",
        "\n",
        "\"#concatenate data into overall data matrix\"  \n",
        "\"#change which vars are in the concatenate block to train/test on a different dataset\"\n",
        "\n",
        "to this - \n",
        "\n",
        "\"psdData = np.concatenate((psd0Blocks, psd1Blocks),axis=0)  \n",
        "psdLabels = np.concatenate((maskPsd0Blocks, maskPsd1Blocks), axis=0) \n",
        "\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3upZ6IcBeBs-"
      },
      "source": [
        "##### RFI DETECTION IN RADIO ASTRONOMY DATA #####\n",
        "##### Morgan Dameron & John McCauley #####\n",
        "\n",
        "##### Gaussian Process Model #####\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.gaussian_process.kernels import Matern\n",
        "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Load PSD Data and Masks (s_16 and TONE)\n",
        "s16_filepath = \"/Data/s_16bit.npy\"\n",
        "s16flag_filepath = \"/Data/s_16bit_flags.npy\"\n",
        "tone_filepath = \"/Data/TONE_Data.npy\"\n",
        "toneflag_filepath = \"/Data/TONE_data_flags.npy\"\n",
        "\n",
        "psd = np.load(s16_filepath) #load the .npy file, filepath may need changed\n",
        "\n",
        "psd0Blocks = np.stack(np.split(psd[:,0:3072,0],6,axis=1)) #split into 127 blocks along the time axis for each polarity\n",
        "psd1Blocks = np.stack(np.split(psd[:,0:3072,1],6,axis=1))\n",
        "\n",
        "psd0Blocks = np.array(psd0Blocks, dtype = np.float32)\n",
        "psd1Blocks = np.array(psd1Blocks, dtype = np.float32)\n",
        "\n",
        "maskPsd = np.load(s16flag_filepath) #load the SK g.t., filepath may need changed\n",
        "\n",
        "\n",
        "Mask0 = np.swapaxes(maskPsd[0:3072,:,0],0,1)\n",
        "Mask1 = np.swapaxes(maskPsd[0:3072,:,1],0,1)\n",
        "\n",
        "#tile ground truth labels to match input size\n",
        "maskLab0 = []\n",
        "maskLab1 = []\n",
        "for i in range(np.shape(Mask0)[0]):\n",
        "  x1 = Mask0[i,:]\n",
        "  y1 = np.tile(x1, (512, 1))\n",
        "  x2 = Mask1[i,:]\n",
        "  y2 = np.tile(x2, (512, 1))\n",
        "  maskLab0.append(np.transpose(y1))\n",
        "  maskLab1.append(np.transpose(y2))\n",
        "\n",
        "maskPsd0Blocks = np.array(maskLab0,dtype=np.float32)\n",
        "maskPsd1Blocks = np.array(maskLab1,dtype=np.float32)\n",
        "\n",
        "tonePsd = np.load(tone_filepath) #load TONE data, filepath may need changed\n",
        "toneMask = np.load(toneflag_filepath) #load TONE SK g.t., filepath may need changed\n",
        "\n",
        "tonePsd0Blocks = np.stack(np.split(tonePsd[:,0:3072,0],6,axis=1)) #split into 127 blocks along the time axis for each polarity\n",
        "tonePsd1Blocks = np.stack(np.split(tonePsd[:,0:3072,1],6,axis=1))\n",
        "\n",
        "tonePsd0Blocks = np.array(tonePsd0Blocks, dtype = np.float32)\n",
        "tonePsd1Blocks = np.array(tonePsd1Blocks, dtype = np.float32)\n",
        "\n",
        "toneMask0 = np.swapaxes(toneMask[0:3072,:,0],0,1)\n",
        "toneMask1 = np.swapaxes(toneMask[0:3072,:,1],0,1)\n",
        "\n",
        "#tile ground truth labels to match input size\n",
        "toneLab0 = []\n",
        "toneLab1 = []\n",
        "for i in range(np.shape(toneMask0)[0]):\n",
        "  x1 = toneMask0[i,:]\n",
        "  y1 = np.tile(x1, (512, 1))\n",
        "  x2 = toneMask1[i,:]\n",
        "  y2 = np.tile(x2, (512, 1))\n",
        "  toneLab0.append(np.transpose(y1))\n",
        "  toneLab1.append(np.transpose(y2))\n",
        "\n",
        "toneMask0Blocks = np.array(toneLab0,dtype=np.float32)\n",
        "toneMask1Blocks = np.array(toneLab1,dtype=np.float32)\n",
        "\n",
        "#concatenate data into overall data matrix\n",
        "#change which vars are in the concatenate block to train/test on a different dataset\n",
        "psdData = np.concatenate((tonePsd0Blocks, tonePsd1Blocks),axis=0) # tonePsd0Blocks, tonePsd1Blocks psd0Blocks, psd1Blocks\n",
        "psdLabels = np.concatenate((toneMask0Blocks, toneMask1Blocks), axis=0) # toneMask0Blocks, toneMask1Blocks maskPsd0Blocks, maskPsd1Blocks\n",
        "\n",
        "del psd, maskPsd, Mask0, Mask1, toneMask0Blocks, toneMask1Blocks, tonePsd, toneMask, maskLab1, toneLab0 #delete all old variables to save on RAM\n",
        "del psd0Blocks, psd1Blocks, maskPsd0Blocks, maskPsd1Blocks, toneMask0, toneMask1, maskLab0, toneLab1\n",
        "\n",
        "#normalize all samples\n",
        "normPsd = []\n",
        "for i in range(np.shape(psdData)[0]):\n",
        "  sample = psdData[i,:,:]\n",
        "  sample = sample - np.min(sample)\n",
        "  sample = sample / np.max(sample)\n",
        "  normPsd.append(sample)\n",
        "\n",
        "normPsd = np.array(normPsd, dtype=np.float32) \n",
        "\n",
        "#reshape samples into univariate time-series\n",
        "dat = []\n",
        "lab = []\n",
        "for i in range(np.shape(normPsd)[0]):\n",
        "  for j in range(1024):\n",
        "    samp = normPsd[i,j,:]\n",
        "    label = psdLabels[i,j,0]\n",
        "    dat.append(samp)\n",
        "    lab.append(label)\n",
        "\n",
        "dat = np.array(dat, dtype=np.float32) \n",
        "lab = np.array(lab, dtype=np.float32)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dat, lab, test_size = 0.2, random_state=42)\n",
        "\n",
        "kern = 1.0 * RationalQuadratic(length_scale=1, alpha=1.5)\n",
        "\n",
        "model = GaussianProcessClassifier(kernel = kern).fit(X_train[0:4096,:], Y_train[0:4096])\n",
        "\n",
        "preds = model.predict(X_test[0:4096,:])\n",
        "\n",
        "print(classification_report(Y_test[0:4096],preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckAeHAagwUXI"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "\n",
        "Section 5. Ancillary Methods\n",
        "\n",
        "---\n",
        "\n",
        "The following blocks of code are additional methods used to generate the figures and visualizations shown in the presentation and report. The comments at the top of each block explain what the block does. Fine tuning of figure spacing is required for good figure generation, as such these methods may not produce readable figures for every data set/data combination without some edits. The values of 'aspect=' and 'plt.subplots_adjust()' can be edited to produce good visualizations.   \n",
        "  \n",
        "For blocks \"##### Visualize outputs, one time block #####\", \"##### Visualize outputs, all time blocks from test set, preds vs true labels #####\", and \"##### Plot one block of preds #####\" - the R-Net code block must be run before running these blocks.\n",
        "\n",
        "For block \"##### Plot Model Loss #####\" - This block can be run after training any of the Neural Network architectures (R-Net, LSTM, CNN-LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGKkcD-de_Z0"
      },
      "source": [
        "##### Visualize outputs, one time block #####\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(3,1)\n",
        "ax1.imshow(preds[0,:,:,0],aspect=0.2)\n",
        "ax1.set_title('Raw Predictions')\n",
        "ax1.set_xlabel('Time Bins')\n",
        "ax1.set_ylabel('Frequency Channels')\n",
        "ax1.invert_yaxis()\n",
        "ax2.imshow(maskedPreds[0,:,:],aspect=0.2)\n",
        "ax2.set_title('Predicted RFI Mask')\n",
        "ax2.set_xlabel('Time Bins')\n",
        "ax2.set_ylabel('Frequency Channels')\n",
        "ax2.invert_yaxis()\n",
        "ax3.imshow(Y_test[0,:,:,0],aspect=0.2)\n",
        "ax3.set_title('Ground Truth RFI Mask')\n",
        "ax3.set_xlabel('Time Bins')\n",
        "ax3.set_ylabel('Frequency Channels')\n",
        "ax3.invert_yaxis()\n",
        "plt.subplots_adjust(top=3.1)\n",
        "plt.savefig('/content/drive/Shareddrives/CS 677/Project/output_tonernet.png',bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPKd_udistpr"
      },
      "source": [
        "##### Visualize outputs, all time blocks from test set, preds vs true labels #####\n",
        "fig, (ax1, ax2) = plt.subplots(2,1)\n",
        "ax1.imshow(np.transpose(reMask),aspect=5)0\n",
        "ax1.set_title('Predicted RFI Mask')\n",
        "ax1.set_xlabel('Time Bins')\n",
        "ax1.set_ylabel('Frequency Channels')\n",
        "ax1.invert_yaxis()\n",
        "plt.subplots_adjust(top=1.01)\n",
        "ax2.imshow(np.transpose(reTrue),aspect=5)\n",
        "ax2.set_title('Ground Truth RFI Mask')\n",
        "ax2.set_xlabel('Time Bins')\n",
        "ax2.set_ylabel('Frequency Channels')\n",
        "ax2.invert_yaxis()\n",
        "plt.savefig('/content/drive/Shareddrives/CS 677/Project/predvgt_s16skrnet.png',bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp1HSzORxfuk"
      },
      "source": [
        "##### Plot one block of preds #####\n",
        "f = plt.figure(1)\n",
        "plt.imshow(np.flipud(preds[0,:,:,0]),aspect=0.1)\n",
        "plt.title(\"Predicted RFI\")\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.savefig('/content/drive/Shareddrives/CS 677/Project/tflabel.png',bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZQj9dujits3"
      },
      "source": [
        "##### Plot Model Loss #####\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train Loss', 'Validation Loss'], loc='upper right')\n",
        "plt.savefig('/content/drive/Shareddrives/CS 677/Project/loss_curve_rnets16sk.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twEMzwQ41n9F"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "\n",
        "Section 6. Appendix - list of required packages\n",
        "\n",
        "---\n",
        "\n",
        "numpy   \n",
        "matplotlib  \n",
        "sklearn  \n",
        "keras  \n",
        "tensorflow  "
      ]
    }
  ]
}